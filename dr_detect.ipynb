{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = 'input/train/' + self.image_arr[index] + '.jpeg'\n",
    "        # Open image\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "        img_as_img = img_as_img.resize((400,300))\n",
    "\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = DRDataset('input/train/trainLabels.csv')\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "print(len(val_loader.dataset))\n",
    "\n",
    "#TODO: Convert datasets to Hdf5: https://stackoverflow.com/questions/32358443/converting-a-dataset-into-an-hdf5-dataset\n",
    "#TODO: Apply style transfer data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0 - No DR\n",
    "1 - Mild\n",
    "2 - Moderate\n",
    "3 - Severe\n",
    "4 - Proliferative DR\n",
    "\"\"\"\n",
    "classes = ('none', 'mild', 'moderate', 'severe', 'proliferative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in train_loader:\n",
    "    for i in range(0, 4):  \n",
    "        im = data[i]\n",
    "        im = torch.squeeze(im)\n",
    "        plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        print(target[i] + \": \" + classes[(int)(target[i])])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = torchvision.models.vgg16() \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=0.005, momentum=0.5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 512)),\n",
    "                           ('relu', nn.ReLU()), \n",
    "                           ('dropout', nn.Dropout(p=0.337)),\n",
    "                           ('fc2', nn.Linear(512, 5)),\n",
    "                           ('output', nn.LogSoftmax(dim=1))\n",
    "                             ]))\n",
    "\n",
    "network.classifier = classifier\n",
    "\n",
    "summary(network, (3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion):\n",
    "    model.train()\n",
    "    current_loss = 0\n",
    "    current_correct = 0\n",
    "    for train, t in iter(loader):\n",
    "        y_train = np.zeros(len(t))\n",
    "        for i in range(len(t)):\n",
    "            y_train[i] = int(t[i])\n",
    "        y_train = torch.from_numpy(y_train).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(train)\n",
    "        _, preds = torch.max(output,1)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()*train.size(0)\n",
    "        current_correct += torch.sum(preds == y_train.data)\n",
    "    epoch_loss = current_loss / len(train_loader.dataset)\n",
    "    epoch_acc = current_correct.double() / len(train_loader.dataset)\n",
    "        \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_correct = 0\n",
    "    for valid, t in iter(loader):\n",
    "        y_valid = np.zeros(len(t))\n",
    "        for i in range(len(t)):\n",
    "            y_valid[i] = int(t[i])\n",
    "        y_valid = torch.from_numpy(y_valid).long()\n",
    "        output = model.forward(valid)\n",
    "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
    "        equal = (output.max(dim=1)[1] == y_valid.data)\n",
    "        valid_correct += torch.sum(equal)#type(torch.FloatTensor)\n",
    "    \n",
    "    epoch_loss = valid_loss / len(val_loader.dataset)\n",
    "    epoch_acc = valid_correct.double() / len(val_loader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in network.parameters():\n",
    "    param.require_grad = False\n",
    "#train and validate\n",
    "epochs = 100  \n",
    "epoch = 0\n",
    "#send model to GPU\n",
    "\n",
    "    \n",
    "for e in range(epochs):\n",
    "    epoch +=1\n",
    "    print(epoch)\n",
    "    with torch.set_grad_enabled(True):\n",
    "        epoch_train_loss, epoch_train_acc = train(network,train_loader, criterion)\n",
    "    print(\"Epoch: {} Train Loss : {:.4f}  Train Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc))\n",
    "with torch.no_grad():\n",
    "    epoch_val_loss, epoch_val_acc = validation(network, val_loader, criterion)\n",
    "    print(\"Epoch: {} Validation Loss : {:.4f}  Validation Accuracy {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()\n",
    "total = 0\n",
    "correct = 0 \n",
    "count = 0\n",
    "#iterating for each sample in the test dataset once\n",
    "for test, t in iter(val_loader):\n",
    "#     test, y_test = test.to('cuda'), y_test.to('cuda')\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    y_test = np.zeros(len(t))\n",
    "    for i in range(len(t)):\n",
    "        y_test[i] = int(t[i])\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    with torch.no_grad():\n",
    "        output = network.forward(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test).sum().item() \n",
    "        count += 1\n",
    "        print(\"Accuracy of network on test images is ... {:.4f}....count: {}\".format(100*correct/total,  count ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'dr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in val_loader:\n",
    "    outputs = network(data)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    for i in range(0, 4):  \n",
    "        im = data[i]\n",
    "        im = torch.squeeze(im)\n",
    "        plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        print(\"TARGET-- \" + target[i] + \": \" + classes[(int)(target[i])])\n",
    "        # print(predicted[i].numpy())\n",
    "        print(\"PREDICTION-- \" + str(predicted[i].numpy()) + \": \" + classes[predicted[i].numpy()])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
